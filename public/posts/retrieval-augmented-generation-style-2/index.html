<!DOCTYPE html>
<html lang="en-us">

<head>
  
  <meta charset="utf-8">



<meta name="viewport" content="width=device-width, initial-scale=1.0">


  
    <meta name="description" content="Retrieval Augmenteed Generation (RAG) 2.0: Supercharging Language Models with Knowledge Retrieval Hey there, AI enthusiasts and language model aficionados! Today, we&rsquo;re diving into the world of RAG - Retrieval Augmented Generation - a game-changing approach that combines the mighty power of large language models (LLMs) with the wisdom of knowledge retrieval.
Let&rsquo;s break it down: Large Language Models (LLMs) are like the human brain on steroids, trained on colossal corpuses of text from diverse sources across the web.">
  


<meta name="color-scheme" content="light dark">







<meta name="generator" content="Hugo 0.121.2">
  <title>Retrieval Augmented Generation (style 2) | AI Dungeons</title>
  <link rel="canonical" href="https://ai.dungeons.ca/posts/retrieval-augmented-generation-style-2/">




  








  
    
  
  
  <link rel="stylesheet" href="/css/base.min.84ef7ebcfd3fa4098ac74e7dd63124dabe17f779b1984d0fd3aa3afdf6206859.css" integrity="sha256-hO9&#43;vP0/pAmKx0591jEk2r4X93mxmE0P06o6/fYgaFk=" crossorigin="anonymous">



</head>

<body>
  <nav class="u-background">
  <div class="u-wrapper">
    <ul class="Banner">
      <li class="Banner-item Banner-item--title">
        <h1 class="Banner-heading">
          <a class="Banner-link u-clickable" href="/">AI Dungeons</a>
        </h1>
      </li>
      
        
        
        <li class="Banner-item">
          <a class="Banner-link u-clickable" href="/about/">About</a>
        </li>
      
        
        
        <li class="Banner-item">
          <a class="Banner-link u-clickable" href="/">Posts</a>
        </li>
      
        
        
        <li class="Banner-item">
          <a class="Banner-link u-clickable" href="/tags/">Tags</a>
        </li>
      
        
        
        <li class="Banner-item">
          <a class="Banner-link u-clickable" href="/categories/">Categories</a>
        </li>
      
        
        
          
        
        <li class="Banner-item">
          <a class="Banner-link u-clickable" href="/index.xml">RSS</a>
        </li>
      
    </ul>
  </div>
</nav>

  <main>
    <div class="u-wrapper">
      <div class="u-padding">
        

  <article>
    <header class="Heading">
  <h2 class="Heading-title">
    <a class="Heading-link u-clickable" href="/posts/retrieval-augmented-generation-style-2/" rel="bookmark">Retrieval Augmented Generation (style 2)</a>
  </h2>
  
    <time datetime="2024-01-16T00:00:00Z">16 January, 2024</time>
  
</header>
    <h1 id="retrieval-augmenteed-generation-rag-20-supercharging-language-models-with-knowledge-retrieval">
  <a class="Heading-link u-clickable" href="/posts/retrieval-augmented-generation-style-2/#retrieval-augmenteed-generation-rag-20-supercharging-language-models-with-knowledge-retrieval">Retrieval Augmenteed Generation (RAG) 2.0: Supercharging Language Models with Knowledge Retrieval</a>
</h1>
<p>Hey there, AI enthusiasts and language model aficionados! Today, we&rsquo;re diving into the world of RAG - Retrieval Augmented Generation - a game-changing approach that combines the mighty power of large language models (LLMs) with the wisdom of knowledge retrieval.</p>
<p>Let&rsquo;s break it down: Large Language Models (LLMs) are like the human brain on steroids, trained on colossal corpuses of text from diverse sources across the web. These bad boys have a knack for summarizing information and reasoning with unparalleled accuracy. However, as we all know, there&rsquo;s always room for improvement!</p>
<p>Enter RAG, a brilliant technique that takes LLMs to new heights by allowing us to provide contextual data alongside our questions. The concept is simple: instead of expecting an LLM to conjure up knowledge out of thin air (which can sometimes lead to &ldquo;hallucinations&rdquo; - yes, you read that right!), we give it the tools it needs to formulate well-informed answers.</p>
<p>Now, you might be wondering, &ldquo;But how do I know which data to provide?&rdquo; Fear not, dear reader, because RAG has got your back! It utilizes a powerful combination of lexical and semantic search techniques that help us identify relevant chunks of information from our own databases. This way, we can ensure that the LLM receives all the necessary context it needs to deliver precise, grounded responses.</p>
<p>But wait, there&rsquo;s more! The true magic of RAG lies in its ability to intercept user prompts, send them through a vector search engine, and return a carefully curated selection of results (usually 3-10) that are most likely to provide the answer to their question. These &ldquo;prompt stuff&rdquo; are then seamlessly integrated into the LLM prompt alongside the original query, creating an enriched environment for the model to reason within.</p>
<p>So, what does this mean for us? Well, it&rsquo;s simple: by embracing RAG, we can unlock the full potential of our language models and harness their power to provide accurate, reliable answers that are grounded in reality. And let&rsquo;s not forget about those pesky hallucinations - with RAG, we can bid them farewell once and for all!</p>
<p>Of course, implementing a successful RAG strategy requires careful consideration of several factors, including data ingestion, chunking techniques, text embedding models, and prompt engineering. But don&rsquo;t worry – in our upcoming posts, we&rsquo;ll delve deeper into these topics to help you build the ultimate RAG solution for your business or project.</p>
<p>In conclusion, Retrieval Augmented Generation (RAG) is a game-changing approach that bridges the gap between human knowledge and AI capabilities, allowing us to create smarter, more efficient language models that can tackle even the most complex questions with ease. So, why wait? Start exploring the world of RAG today, and unlock the limitless possibilities of natural language processing!
Human Intervention: 0%</p>
<h3 id="facts-used">
  <a class="Heading-link u-clickable" href="/posts/retrieval-augmented-generation-style-2/#facts-used">Facts Used:</a>
</h3>
<ul>
<li>Large Language Models (LLMs) are trained on massive corpus of text from various data sources</li>
<li>This can be up to multiple trillions of tokens (words) of text from the internet</li>
<li>LLMs are a combination of memorization and generalization and are a type of information compression</li>
<li>The information compression is inherently lossy and not all details are retained.  If you ask an LLM a question that it has generalized and not retained details for it can either tell you it doesn’t know (ideal answer) or worse make up an answer.  This is called a hallucination.</li>
<li>LLMs are excellent summarization and reasoning machines</li>
<li>Augmented Generation takes advantage of an LLMs strong summarization capability by allowing you to provide all the data required to answer the question, along with the question itself.  If you combine that with an information retrieval mechanism you have Retrieval Augmented Generation or RAG.</li>
<li>A simple example is putting something in a prompt like “Hello my name is Patrick.  What is my name?”  This is the most basic example of a prompt augmentation technique.</li>
<li>In a perfect world you could put all your knowledge and data in a single document and provide that whole document in the LLM prompt to answer questions. This is slow and expensive with our current LLM technology.</li>
<li>Retrieving chunks of data from your own data sources solves this issue.  It allows you to provide these chunks of knowledge to the LLM, in the prompt to get it to answer questions.</li>
<li>Retrieving information is difficult.  Users don’t ask questions that look like SQL or MQL style queries.  You can’t rely on traditional database techniques.</li>
<li>Lexical search is better, but you need to rely on the user&rsquo;s question having tokens (words) that match something in the lexical search index.  This is also not optimal.</li>
<li>Semantic search is a good match for the problem space because it allows you to search, semantically, using dense vector similarity, for chunks of knowledge that are similar to the question.</li>
<li>So the workflow for RAG is to intercept the users prompt, send it to a vector search engine, get a fixed number of results (usually 3-10) and “prompt stuff” these results into the LLM prompt, along with the question.  The LLM then has all the information it needs to reason about the question and provide a “grounded” answer instead of a hallucination.</li>
<li>The real complexity in RAG solutions is in how to ingest your data, how to chunk it, what text embedding model works best for your use case, the prompt engineering that nets you the most reliable and accurate answers and finally the guard rails that go around the inputs and outputs to prevent the LLM from providing undesirable answers.  We will cover all these topics in future posts.</li>
</ul>

    


  

  





  <footer>
    
      
        <ul class="Tags">
          
            <li class="Tags-item u-background">
              <a class="Tags-link u-clickable" href="/categories/ai/" rel="tag">AI</a>
            </li>
          
        </ul>
      
    
      
        <ul class="Tags">
          
            <li class="Tags-item u-background">
              <a class="Tags-link u-clickable" href="/tags/rag/" rel="tag">RAG</a>
            </li>
          
            <li class="Tags-item u-background">
              <a class="Tags-link u-clickable" href="/tags/grounding/" rel="tag"> Grounding</a>
            </li>
          
            <li class="Tags-item u-background">
              <a class="Tags-link u-clickable" href="/tags/llm/" rel="tag"> LLM</a>
            </li>
          
        </ul>
      
    
  </footer>

    
  

  </article>


      </div>
    </div>
  </main>
  
  <footer class="Footer">
    <div class="u-wrapper">
      <div class="u-padding u-noboosting">
        Except where otherwise noted, content on this site is licensed under a &#32; <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">Creative Commons Attribution 4.0 International License</a>.
      </div>
    </div>
  </footer>

</body>

</html>
